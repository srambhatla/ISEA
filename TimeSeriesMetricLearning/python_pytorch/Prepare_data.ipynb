{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EEG-UCI\n",
    "Unzip the file first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import scipy as sp\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EEG-UCI\n",
    "base_folder = '../new_data/SMNI_CMI_TRAIN/'\n",
    "r = os.walk(base_folder)\n",
    "_, d, _ = list(r)[0]  \n",
    "\n",
    "data_folder = 'co2a0000368'\n",
    "f = list(os.walk(base_folder + str(d[0])))\n",
    "\n",
    "L = 0\n",
    "for directory in tqdm(d):\n",
    "    f = list(os.walk(base_folder + str(directory)))\n",
    "    #print(directory)\n",
    "    for file in f[0][2]:\n",
    "        if file[-2:] != 'gz':\n",
    "            L = L + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.empty((L,1), dtype=object)\n",
    "#X = []\n",
    "i = 0\n",
    "y = []\n",
    "t = []\n",
    "for directory in tqdm(d):\n",
    "    f = list(os.walk(base_folder + str(directory)))\n",
    "    #print(directory)\n",
    "    for file in f[0][2]:\n",
    "        if file[-2:] != 'gz':\n",
    "            file_name = '../new_data/SMNI_CMI_TRAIN/' + directory + '/' + file\n",
    "            #print(file_name)\n",
    "            df = pd.read_csv(file_name, delimiter=' ', skiprows=4, names=['#', 'feat', 'seq', 'val'] )\n",
    "            \n",
    "            if directory[3] == 'a':\n",
    "                lbl = 1\n",
    "            else:\n",
    "                lbl = 0\n",
    "                \n",
    "            y.append(lbl)\n",
    "                \n",
    "            # Features\n",
    "            feats = np.unique(df['feat'].values)\n",
    "            sam = []\n",
    "            for chan in feats:\n",
    "                sam.append(df[df['feat'] == chan]['val'].values[1:])\n",
    "\n",
    "            sam = np.array(sam, dtype=float).T\n",
    "            X[i] = [sam[::8]] \n",
    "            t.append(X[i][0].shape[0])\n",
    "            #X.append([sam])\n",
    "            i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare folds\n",
    "arr = np.arange(len(np.array(y).T))\n",
    "np.random.shuffle(arr)\n",
    "partitions = np.array_split(arr, 5)\n",
    "I = np.zeros(len(np.array(y).T),dtype='uint8')\n",
    "for i in range(0,5):\n",
    "    I[partitions[i]] = i+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = {}\n",
    "dat['X'] = X\n",
    "dat['y'] = y\n",
    "dat['T'] = t\n",
    "\n",
    "fol = {}\n",
    "fol['folds'] = np.expand_dims(I,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sio.savemat(\"../new_data/ucieeg-new/ucieeg-new.mat\", dat)\n",
    "#sio.savemat(\"../new_data/ucieeg-new/ucieeg-new-5folds.mat\", fol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = sio.loadmat(\"../new_data/ucieeg-new/ucieeg-new.mat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat['X'][0][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Physionet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import scipy as sp\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import random\n",
    "from sklearn.impute import SimpleImputer\n",
    "np.random.seed(0)\n",
    "\n",
    "out_name = 'physio-data'\n",
    "base_folder = '../new_data/physionet-data/set-a/'\n",
    "outcomes = pd.read_csv(base_folder[:-6]+ 'Outcomes-a.txt')\n",
    "\n",
    "r = os.walk(base_folder)\n",
    "_, _, f = list(r)[0]  \n",
    "#L = len(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_class = outcomes[outcomes['In-hospital_death'] == 1]['RecordID'].values\n",
    "neg_class = outcomes[outcomes['In-hospital_death'] == 0]['RecordID'].values\n",
    "sam_neg_class = random.sample(list(neg_class), len(pos_class))\n",
    "sam_recs = list(pos_class) + sam_neg_class\n",
    "random.shuffle(sam_recs)\n",
    "L = len(sam_recs)\n",
    "sam_files = [str(rec) + '.txt' for rec in sam_recs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = ['Albumin', \n",
    "    'ALP', \n",
    "    'ALT', \n",
    "    'AST',\n",
    "    'Bilirubin',\n",
    "    'BUN', \n",
    "    'Cholesterol',\n",
    "    'Creatinine',\n",
    "    'DiasABP',\n",
    "    'FiO2',\n",
    "    'GCS', \n",
    "    'Glucose', \n",
    "    'HCO3', \n",
    "    'HCT', \n",
    "    'HR', \n",
    "    'K', \n",
    "    'Lactate', \n",
    "    'Mg', \n",
    "    'MAP', \n",
    "    'MechVent', \n",
    "    'Na', \n",
    "    'NIDiasABP',\n",
    "    'NIMAP',\n",
    "    'NISysABP', \n",
    "\t'PaCO2',\n",
    "    'PaO2', \n",
    "    'pH', \n",
    "    'Platelets',\n",
    "    'RespRate',\n",
    "    'SaO2', \n",
    "    'SysABP', \n",
    "    'Temp',    \n",
    "    'TropI',\n",
    "    'TropT',\n",
    "    'Urine',\n",
    "    'WBC',\n",
    "    'Weight']\n",
    "len(feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "def hr_conv(a):\n",
    "    return int(a[0:2])\n",
    "\n",
    "X = np.empty((L,1), dtype=object)\n",
    "#X = []\n",
    "i = 0\n",
    "y = []\n",
    "t = []\n",
    "seen_feats = []\n",
    "#for directory in tqdm(d):\n",
    "#    f = list(os.walk(base_folder + str(directory)))\n",
    "    #print(directory)\n",
    "track_max = []\n",
    "for file in sam_files:\n",
    "    if file[-3:] == 'txt':\n",
    "        file_name = base_folder + file\n",
    "            #print(file_name)\n",
    "        df = pd.read_csv(file_name, delimiter=',', skiprows=6, names=['time', 'feat', 'val'])\n",
    "        df['hour'] = list(map(hr_conv, df['time'].values))\n",
    "        track_max.append(max(df['hour']))\n",
    "        if max(df['hour']) == 49:\n",
    "            \n",
    "            break\n",
    "                 \n",
    "        y.append(outcomes[outcomes['RecordID'] == int(file[:-4])]['In-hospital_death'].values[0])\n",
    "        \n",
    "      \n",
    "        # Features\n",
    "        #feats = np.unique(df['feat'].values)\n",
    "        seen_feats.append(list(np.unique(df['feat'].values)))\n",
    "        sam = []\n",
    "        for chan in feats:\n",
    "            \n",
    "            if df[df['feat'] == chan].empty:\n",
    "                sen_dat = np.zeros([49,1])\n",
    "                sam.append(sen_dat)\n",
    "            else:\n",
    "                sen_dat = np.empty([49,1])\n",
    "                sen_dat[:] = np.nan\n",
    "                sen_dat[list(df[df['feat'] == chan].groupby('hour').groups.keys())] = df[df['feat'] == chan].groupby('hour').mean().values\n",
    "\n",
    "            \n",
    "                sam.append(imp.fit_transform(sen_dat))\n",
    "        \n",
    "        sam = np.squeeze(np.array(sam, dtype=float).T)\n",
    "        X[i] = [sam] \n",
    "        t.append(sam.shape[0])\n",
    "         #X.append([sam])\n",
    "        i = i + 1\n",
    "\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare folds\n",
    "arr = np.arange(len(np.array(y).T))\n",
    "np.random.shuffle(arr)\n",
    "partitions = np.array_split(arr, 5)\n",
    "I = np.zeros(len(np.array(y).T),dtype='uint8')\n",
    "for i in range(0,5):\n",
    "    I[partitions[i]] = i+1\n",
    "\n",
    "dat = {}\n",
    "dat['X'] = X\n",
    "dat['y'] = y\n",
    "dat['T'] = t\n",
    "\n",
    "fol = {}\n",
    "\n",
    "fol['folds'] = np.expand_dims(I,0)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sio.savemat('../new_data/' + out_name + '/' + out_name + '.mat', dat)\n",
    "#sio.savemat('../new_data/' + out_name + '/' + out_name + '-5folds.mat', fol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from argparse import ArgumentParser\n",
    "import pickle\n",
    "np.random.seed(0)\n",
    "\n",
    "\n",
    "\n",
    "os.chdir('../new_data/RAS/')\n",
    "from utils import process_entry\n",
    "import dataloaders\n",
    "#parser = ArgumentParser()\n",
    "#parser.add_argument('--input_kinema28062466tics_folder', type=str, default='../new_data/RAS')\n",
    "#args = parser.parse_args()\n",
    "\n",
    "#input_kinematics_folder = args.input_kinematics_folder\n",
    "input_kinematics_folder ='../../new_data/RAS/kinematics/'\n",
    "input_videos_folder = '../multi_modal/processed_data/videos/' # <path_to_videos>\n",
    "\n",
    "tasks_names = ['AB_label_needle_positionB', 'BC_label_needle_entry_angleC', 'CD_label_needle_driving_1D', 'FG_label_needle_driving_2FG']\n",
    "\n",
    "out_name = 'ras-data-bcea'\n",
    "task_names = [tasks_names[1] ]\n",
    "task_abbrv = ''\n",
    "\n",
    "i = 0\n",
    "\n",
    "for task_name in task_names:\n",
    "    task_file = task_name + str('.p')\n",
    "   \n",
    "    data_f = pickle.load( open( input_kinematics_folder+'{}'.format(task_file), \"rb\" ) )#.format(args.task_file), \"rb\" ) )\n",
    "    \n",
    "    if task_abbrv != '' :\n",
    "        data_p = {k + '_' + task_abbrv[i]:(process_entry(v1),v2) for k,(v1,v2) in data_f.items()}\n",
    "    else:\n",
    "        data_p = {k:(process_entry(v1),v2) for k,(v1,v2) in data_f.items()}\n",
    "           \n",
    "    data_loader = dataloaders.SpatialDataloader(batch_size=32,\n",
    "                                            num_workers=8,\n",
    "                                            data_path=os.path.join(input_videos_folder, task_name),\n",
    "                                            #seed=args.seed)\n",
    "                                            seed=42)\n",
    "    \n",
    "    _, _, test_video_p = data_loader.run()\n",
    "\n",
    "    \n",
    "    if task_abbrv != '' :\n",
    "        test_video_p = {k + '_' + task_abbrv[i]:int(v) for k,v in test_video_p.items()}\n",
    "    \n",
    "    \n",
    "    \n",
    "    if i == 0:\n",
    "        data = dict(data_p)\n",
    "        test_video = dict(test_video_p)\n",
    "        \n",
    "    else:\n",
    "        data.update(data_p)\n",
    "        test_video.update(test_video_p)\n",
    "    \n",
    "\n",
    "        \n",
    "    i = i + 1\n",
    "    \n",
    "sequence_lengths = [data[row][0].shape[0] for row in data]\n",
    "trunc_len = int(np.percentile(sequence_lengths, 95))\n",
    "V, X, y = [], [], []\n",
    "\n",
    "for row in data:\n",
    "    V.append(row)\n",
    "    #X.append(torch.from_numpy(data[row][0][-trunc_len:]).float())   \n",
    "    X.append(torch.from_numpy(data[row][0]).float()) \n",
    "    y.append(data[row][1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[x.shape[0] for x in X]\n",
    "int(np.percentile(sequence_lengths, 50))\n",
    "plt.hist(sequence_lengths, 150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "seq_len = [X[i].shape[0] for i in range(0, len(X))]\n",
    "low = 2\n",
    "high = np.max(seq_len)\n",
    "L = np.sum([(X[i].shape[0] > low) & (X[i].shape[0] <= high) for i in range(0, len(X))])\n",
    "Xx = np.empty((L,1), dtype=object)\n",
    "#X = []\n",
    "i = 0\n",
    "yy = []\n",
    "t = []\n",
    "ii = 0\n",
    "d = 0\n",
    "for x in X:\n",
    "    sam = np.array(x.cpu().numpy(), dtype=float)\n",
    "    #sam = np.array(x, dtype=float).T\n",
    "    \n",
    "    if (sam.shape[0] > low) & (sam.shape[0] <= high):\n",
    "       # print(sam.shape)\n",
    "        Xx[ii] = [sam] \n",
    "        yy.append(int(y[i]))\n",
    "        t.append(sam.shape[0])\n",
    "         #X.append([sam])\n",
    "        ii = ii + 1\n",
    "    else:\n",
    "        d = d + 1\n",
    "    i = i + 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare folds\n",
    "arr = np.arange(len(np.array(yy).T))\n",
    "np.random.shuffle(arr)\n",
    "partitions = np.array_split(arr, 5)\n",
    "I = np.zeros(len(np.array(yy).T),dtype='uint8')\n",
    "for i in range(0,5):\n",
    "    I[partitions[i]] = i+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = {}\n",
    "dat['X'] = Xx\n",
    "dat['y'] = yy\n",
    "dat['T'] = t\n",
    "\n",
    "fol = {}\n",
    "fol['folds'] = np.expand_dims(I,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#sio.savemat('../new_data/' + out_name + '/' + out_name + '.mat', dat)\n",
    "#sio.savemat('../new_data/' + out_name + '/' + out_name + '-5folds.mat', fol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = sio.loadmat(\"../new_data/ras-data/ras-data.mat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(X[2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asphalt Regularity Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import scipy as sp\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import random\n",
    "from sklearn.impute import SimpleImputer\n",
    "import h5py\n",
    "from scipy.io import arff\n",
    "np.random.seed(0)\n",
    "\n",
    "out_name = 'ucr-data-aspreg'\n",
    "base_folder = '../sdtw_data' # <path_to_data>\n",
    " \n",
    "r = os.walk(base_folder)\n",
    "_, f, _ = list(r)[0]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name_tr = base_folder+ '/' + 'AsphaltRegularity' + '/' + 'AsphaltRegularity' + '_TRAIN.arff'\n",
    "file_name_te = base_folder+ '/' + 'AsphaltRegularity' + '/' + 'AsphaltRegularity' + '_TEST.arff'\n",
    "dat_arff_tr = arff.loadarff(file_name_tr)\n",
    "dat_arff_te = arff.loadarff(file_name_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_tr = pd.DataFrame(dat_arff_tr[0])\n",
    "dat_te = pd.DataFrame(dat_arff_te[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_tr.target = pd.factorize(dat_tr.target)[0]\n",
    "dat_te.target = pd.factorize(dat_te.target)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([dat_tr, dat_te], axis=0)\n",
    "data = data.reset_index(drop=True)\n",
    "labels = list(data['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['target'], axis=1)\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = data.shape[0]\n",
    "X = np.empty((L,1), dtype=object)\n",
    "#X = []\n",
    "i = 0\n",
    "y = []\n",
    "t = []\n",
    "\n",
    "for i in range(0, data.shape[0]):\n",
    "    y.append(labels[i])\n",
    "    sam = np.squeeze(np.array(list(data.iloc[i][data.iloc[i].notnull()].T)))\n",
    "    sam = np.expand_dims(sam, 1)\n",
    "    X[i] = [sam] \n",
    "    t.append(sam.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare folds\n",
    "arr = np.arange(len(np.array(y).T))\n",
    "np.random.shuffle(arr)\n",
    "partitions = np.array_split(arr, 5)\n",
    "I = np.zeros(len(np.array(y).T),dtype='uint8')\n",
    "for i in range(0,5):\n",
    "    I[partitions[i]] = i+1\n",
    "\n",
    "dat = {}\n",
    "dat['X'] = X\n",
    "dat['y'] = y\n",
    "dat['T'] = t\n",
    "\n",
    "fol = {}\n",
    "\n",
    "fol['folds'] = np.expand_dims(I,0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sio.savemat('../new_data/' + out_name + '/' + out_name + '.mat', dat)\n",
    "#sio.savemat('../new_data/' + out_name + '/' + out_name + '-5folds.mat', fol)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
